{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T10:04:29.954766Z",
     "start_time": "2025-05-13T10:04:25.755960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Pre-processing functions\n",
    "from src.data.data_helper import get_raw_data_as_dataframe\n",
    "from src.models.preprocessing.preprocessor import SignalPreprocessor\n",
    "from src.data.data_helper import segement_data\n",
    "\n",
    "# Model functions\n",
    "from src.models.LSTM.LSTM import LSTM\n",
    "from src.models.LSTM_STFT.LSTM_STFT import LSTM_STFT\n",
    "from src.models.LSTM_STFT_Dense.LSTM_STFT_Dense import LSTM_STFT_Dense"
   ],
   "id": "f41472cd74952d54",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T10:04:30.154864Z",
     "start_time": "2025-05-13T10:04:30.147807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_training_data():\n",
    "    raw_train, raw_val = get_raw_data_as_dataframe(\n",
    "        validation_subjects=(1,2)\n",
    "    )\n",
    "\n",
    "    # Initialize the preprocessor\n",
    "    pre_processor = SignalPreprocessor(\n",
    "        low_freq=20.0,\n",
    "        high_freq=500.0,\n",
    "        fs=5000.0,\n",
    "        order=7\n",
    "    )\n",
    "    # Calibrate the preprocessor\n",
    "    pre_processor.calibrate(raw_train)\n",
    "\n",
    "    window_length=200 * 5\n",
    "    overlap=50 * 5\n",
    "\n",
    "    seg_train = segement_data(\n",
    "        raw_train, window_length=window_length, overlap=overlap\n",
    "    )\n",
    "    seg_val = segement_data(\n",
    "        raw_val,   window_length=window_length, overlap=overlap\n",
    "    )\n",
    "\n",
    "    all_labels = pd.concat([seg_train['label'], seg_val['label']])\n",
    "    num_classes = all_labels.nunique()\n",
    "\n",
    "    y_train = tf.keras.utils.to_categorical(\n",
    "        seg_train['label'].values, num_classes=num_classes\n",
    "    )\n",
    "    y_val = tf.keras.utils.to_categorical(\n",
    "        seg_val['label'].values,  num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    X_train = np.stack(seg_train.drop(columns=['label', 'source'])['window_data'].values)\n",
    "    X_val   = np.stack(seg_val.drop(columns=['label', 'source'])['window_data'].values)\n",
    "\n",
    "    X_train = pre_processor.batch_pre_process(X_train)\n",
    "    X_val   = pre_processor.batch_pre_process(X_val)\n",
    "\n",
    "    input_shape = X_train.shape[1]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, num_classes, input_shape"
   ],
   "id": "305ae0daa69fab3b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T10:04:49.115741Z",
     "start_time": "2025-05-13T10:04:30.166301Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, y_train, X_val, y_val, num_classes, input_shape = get_training_data()",
   "id": "19c8ec7c01c59989",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T10:04:49.285811Z",
     "start_time": "2025-05-13T10:04:49.137846Z"
    }
   },
   "cell_type": "code",
   "source": "import keras_tuner as kt",
   "id": "196c98fba052276e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T10:06:04.968938Z",
     "start_time": "2025-05-13T10:06:04.956771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMHyperModel(kt.HyperModel):\n",
    "\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    # ----------------- build -----------------------------------------\n",
    "    def build(self, hp):\n",
    "        lr = hp.Float('learning_rate', 1e-4, 5e-2, sampling='log')\n",
    "\n",
    "        opt  = hp.Choice('optimizer',\n",
    "                         values=['adam', 'rmsprop', 'nadam'])\n",
    "\n",
    "        norm = hp.Choice('normalization',\n",
    "                         values=['none', 'batch', 'layer'])\n",
    "\n",
    "        dropout           = hp.Float('dropout',           0.0, 0.5, step=0.1)\n",
    "        recurrent_dropout = hp.Float('recurrent_dropout', 0.0, 0.5, step=0.1)\n",
    "\n",
    "        act_dense = hp.Choice('act_dense', ['tanh', 'relu'])\n",
    "        act_lstm  = hp.Choice('act_lstm',  ['tanh', 'relu'])\n",
    "\n",
    "        # We only declare batch_size here; we'll use it in fit().\n",
    "        hp.Choice('batch_size', values=[32, 64, 128, 256, 512])\n",
    "\n",
    "        model = LSTM(\n",
    "            input_shape      = self.input_shape,\n",
    "            num_classes      = self.num_classes,\n",
    "            learning_rate    = lr,\n",
    "            optimizer        = opt,\n",
    "            normalization    = norm,\n",
    "            dropout          = dropout,\n",
    "            recurrent_dropout= recurrent_dropout,\n",
    "            act_dense        = act_dense,\n",
    "            act_lstm         = act_lstm\n",
    "        ).get_model()\n",
    "\n",
    "        return model\n",
    "\n",
    "    # ----------------- fit -------------------------------------------\n",
    "    def fit(self, hp, model, X_train, y_train, X_val, y_val, **kwargs):\n",
    "        \"\"\"\n",
    "        Called by the tuner for every trial.  We inject the per-trial\n",
    "        batch_size coming from hp.\n",
    "        \"\"\"\n",
    "        batch_size = hp.get('batch_size')\n",
    "        return model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            batch_size=batch_size,\n",
    "            epochs=kwargs.get('epochs', 10),\n",
    "            verbose=kwargs.get('verbose', 2)\n",
    "        )"
   ],
   "id": "c79576dba368e314",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T10:06:06.707458Z",
     "start_time": "2025-05-13T10:06:06.704295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_f1_score',      # metric name Keras assigns: ‘f1_score’\n",
    "    mode='max',                  # we want to maximise it\n",
    "    patience=5,\n",
    "    restore_best_weights=True)"
   ],
   "id": "3b49c0f097fba9f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T10:06:09.752620Z",
     "start_time": "2025-05-13T10:06:09.748624Z"
    }
   },
   "cell_type": "code",
   "source": "hypermodel = LSTMHyperModel(input_shape, num_classes)",
   "id": "58ec55430db62dc4",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T10:06:10.083944Z",
     "start_time": "2025-05-13T10:06:10.075966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils.path_utils import get_models_dir\n",
    "\n",
    "model_dir = get_models_dir() / \"LSTM_search\"\n",
    "model_dir"
   ],
   "id": "98f2f625c1de8688",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/erik/IES_codebase/EMG_Project/CDT406-Smart-Gripper/models/LSTM_search')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T10:06:10.609140Z",
     "start_time": "2025-05-13T10:06:10.561109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    hypermodel,\n",
    "    objective = kt.Objective(\"val_f1_score\", direction=\"max\"),\n",
    "    max_trials=50,\n",
    "    directory=model_dir,\n",
    "    project_name=\"baseline_v2\",\n",
    "    overwrite=True\n",
    ")"
   ],
   "id": "d526ca1e149121df",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             X_val=X_val, y_val=y_val,\n",
    "             callbacks=[stop_early],\n",
    "             epochs=30,\n",
    "             verbose=2)"
   ],
   "id": "c643dfb1ea10de35",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 24s]\n",
      "val_f1_score: 0.48329830169677734\n",
      "\n",
      "Best val_f1_score So Far: 0.6024924516677856\n",
      "Total elapsed time: 00h 01m 36s\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T10:05:38.447936Z",
     "start_time": "2025-05-13T10:05:38.441421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ],
   "id": "d0852abe3e47bf7c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T10:09:44.126754Z",
     "start_time": "2025-05-13T10:09:44.118777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Best hyper-parameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Corresponding trial (contains metrics)\n",
    "best_trial   = tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_val_f1  = best_trial.metrics.get_best_value('val_f1_score')\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "\n",
    "Optimal learning rate     : {best_hps.get('learning_rate')}\n",
    "Optimal optimizer         : {best_hps.get('optimizer')}\n",
    "Optimal normalization     : {best_hps.get('normalization')}\n",
    "Optimal batch size        : {best_hps.get('batch_size')}\n",
    "Optimal dropout           : {best_hps.get('dropout')}\n",
    "Optimal recurrent dropout : {best_hps.get('recurrent_dropout')}\n",
    "Optimal dense activation  : {best_hps.get('act_dense')}\n",
    "Optimal LSTM activation   : {best_hps.get('act_lstm')}\n",
    "Best validation F1-score  : {best_val_f1:.4f}\n",
    "\"\"\")"
   ],
   "id": "6b7b54b5a9f6afdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete.\n",
      "\n",
      "Optimal learning rate     : 0.0001009429310439601\n",
      "Optimal optimizer         : nadam\n",
      "Optimal normalization     : batch\n",
      "Optimal batch size        : 32\n",
      "Optimal dropout           : 0.2\n",
      "Optimal recurrent dropout : 0.4\n",
      "Optimal dense activation  : tanh\n",
      "Optimal LSTM activation   : relu\n",
      "Best validation F1-score  : 0.6025\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
