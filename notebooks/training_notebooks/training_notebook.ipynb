{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "This section contains all necessary setup such as libraries and model creation."
   ],
   "id": "cce7ad94f634b73e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.data.data_helper import get_raw_data_as_dataframe"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "raw_data = get_raw_data_as_dataframe()\n",
    "raw_data.head()"
   ],
   "id": "6216f39a6c77b17e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "raw_data.shape",
   "id": "94a17ceba516f1fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pre-processor Calibration\n",
    "Due to the fact that all data needs to be pre-processed using the same bandpass filter and normalization the pre-processor needs to be calibrated. This is done by calculating the coefficients of the bandpass filter and the normalization parameters.\n",
    "\n",
    "These parameters will then be passed to the selected model class."
   ],
   "id": "1cbd0adaf97c5d08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.models.preprocessing.preprocessor import SignalPreprocessor\n",
    "\n",
    "pre_processor = SignalPreprocessor(\n",
    "    low_freq=20.0, # Maybe try down to 17.\n",
    "    high_freq=500.0, # Around 100-150 looks good for our data.\n",
    "    fs=5000.0,\n",
    "    order=7\n",
    ")"
   ],
   "id": "17efca2c8504cf75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pre_processor.calibrate(raw_data)",
   "id": "413737e8d43acd15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Parsing\n",
    "This section deals with segmenting the data into usable segements with correct labeling. After that we pre-process the data using the pre-processor which is valibrated above. Once the data is pre-processed we apply one-hot encoding to the labels to allow for the use of F1 score. Finally we split the data into training and validation sets."
   ],
   "id": "28cf388cb7fbe339"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from src.data.data_helper import segement_data",
   "id": "18d5222402ca9312",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "segmented_data = segement_data(raw_data, window_length=200*5, overlap=50*5)",
   "id": "3531f31ce693ce49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "segmented_data.head()",
   "id": "8e9cbe99d0d9531c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "segmented_data.iloc[1000]",
   "id": "26994063576a24b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_classes = segmented_data['label'].nunique()\n",
    "num_classes"
   ],
   "id": "2b5473d721ae9feb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_data = np.array(segmented_data['label'].values)\n",
    "y_data = tf.keras.utils.to_categorical(y_data, num_classes=num_classes)\n",
    "\n",
    "# I apologize for this horrible line. Can be fixed by fixing the data_helper\n",
    "X_data = np.stack(segmented_data.drop(columns=['label', 'source'])['window_data'].values)"
   ],
   "id": "f48efd56054d20af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_data.shape",
   "id": "e6d3308abdb1c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_data = pre_processor.batch_pre_process(X_data)\n",
    "X_data.shape"
   ],
   "id": "92fb2b904eede463",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_data.shape",
   "id": "79f42ccce1725a68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_data, y_data, test_size=0.2\n",
    "    )"
   ],
   "id": "28e482d0c9eb57fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.shape",
   "id": "92e58a2c114018c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_val.shape",
   "id": "977cf7e899fae65a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analysis and Fixing of Imblanaces in Labels",
   "id": "69a206fb6fdaf19d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label_percentages = segmented_data['label'].value_counts(normalize=True).sort_index() * 100\n",
    "print(label_percentages)"
   ],
   "id": "a6fb4c276e92f7de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot label distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "segmented_data['label'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.show()"
   ],
   "id": "489f2d9cf6cce6c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "labels = np.argmax(y_train, axis=1)\n",
    "unique, counts = np.unique(labels, return_counts=True)"
   ],
   "id": "276f36a80b1ff4b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "labels.shape[0]",
   "id": "aee2013e958c26cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "unique",
   "id": "cffdc58033a88baa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "counts",
   "id": "2c80f131e45027c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / counts[0]) * (labels.shape[0] / 2.0)\n",
    "weight_for_1 = (1 / counts[1]) * (labels.shape[0] / 2.0)\n",
    "weight_for_2 = (1 / counts[2]) * (labels.shape[0] / 2.0)\n",
    "weight_for_3 = (1 / counts[3]) * (labels.shape[0] / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2, 3: weight_for_3}\n",
    "class_weight"
   ],
   "id": "98bffaf7521adce4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "# ros = RandomUnderSampler(random_state=0)\n",
    "# smote = SMOTE(random_state=0)\n",
    "\n",
    "# X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "# X_train, y_train = smote.fit_resample(X_train, y_train)"
   ],
   "id": "2b051a8a83068cc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.shape",
   "id": "258e4ed39ea42e77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot label distribution for resampled training data\n",
    "plt.figure(figsize=(8, 4))\n",
    "labels_resampled = np.argmax(y_train, axis=1)\n",
    "unique, counts = np.unique(labels_resampled, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels (Resampled Training Data)')\n",
    "plt.show()"
   ],
   "id": "83253968b74a4121",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train.shape",
   "id": "99f214a3fdcd371",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_val.shape",
   "id": "9c0ead5caab95d71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Setup\n",
    "Import model classes and create instances of the models."
   ],
   "id": "95d03be02b8ddfad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "e7c1eefc89cadf2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 512\n",
    "epochs = 20\n",
    "\n",
    "learning_rate = 1e-3"
   ],
   "id": "78f0c3ad9bf61190",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Creation",
   "id": "666616d6e02682c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.models.LSTM.LSTM import LSTM\n",
    "from src.models.LSTM_STFT.LSTM_STFT import LSTM_STFT\n",
    "from src.models.LSTM_STFT_Dense.LSTM_STFT_Dense import LSTM_STFT_Dense"
   ],
   "id": "6b5bfb3fa23c22bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "LSTM_model = LSTM(\n",
    "    input_shape=X_data.shape[1],\n",
    "    num_classes=num_classes,\n",
    "    learning_rate=learning_rate\n",
    ")"
   ],
   "id": "6695f94cd11817a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "LSTM_STFT_model = LSTM_STFT(\n",
    "    input_shape=X_data.shape[1],\n",
    "    num_classes=num_classes,\n",
    "    learning_rate=learning_rate\n",
    ")"
   ],
   "id": "f61a86083a6bafaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "LSTM_STFT_Dense_model = LSTM_STFT_Dense(\n",
    "    input_shape=X_data.shape[1],\n",
    "    num_classes=num_classes,\n",
    "    learning_rate=learning_rate\n",
    ")"
   ],
   "id": "49df3edd702db6d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train Model\n",
    "Train the models"
   ],
   "id": "e612d4063d25f585"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "LSTM_model.get_model().fit(X_train, y_train,\n",
    "                       validation_data=(X_val, y_val),\n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       verbose=2,\n",
    "                       class_weight=class_weight\n",
    "                    )"
   ],
   "id": "579ce5c344a75a1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "LSTM_STFT_model.get_model().fit(X_train, y_train,\n",
    "                       validation_data=(X_val, y_val),\n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       verbose=2,\n",
    "                       class_weight=class_weight\n",
    "                    )"
   ],
   "id": "5c30cae49d752c96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "LSTM_STFT_Dense_model.get_model().fit(X_train, y_train,\n",
    "                       validation_data=(X_val, y_val),\n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       verbose=2,\n",
    "                       class_weight=class_weight\n",
    "                    )"
   ],
   "id": "8007e58e81f4c2aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plotting",
   "id": "3e12394302777b8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from src.visualizations.plot_learning_curves import plot_learning_curves, plot_confusion_and_f1",
   "id": "f7598bcecfb73d7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_learning_curves(LSTM_model.get_model(), plot_title=LSTM_model.get_model_name())\n",
    "plot_confusion_and_f1(LSTM_model.get_model(), X_val, y_val, plot_title=LSTM_model.get_model_name())"
   ],
   "id": "dd03af42a0367412",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_learning_curves(LSTM_STFT_model.get_model(), plot_title=LSTM_STFT_model.get_model_name())\n",
    "plot_confusion_and_f1(LSTM_STFT_model.get_model(), X_val, y_val, plot_title=LSTM_STFT_model.get_model_name())"
   ],
   "id": "c3813f063407adfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_learning_curves(LSTM_STFT_Dense_model.get_model(), plot_title=LSTM_STFT_Dense_model.get_model_name())\n",
    "plot_confusion_and_f1(LSTM_STFT_Dense_model.get_model(), X_val, y_val, plot_title=LSTM_STFT_Dense_model.get_model_name())"
   ],
   "id": "d06cdec3618fc7e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b3b198964cc71438",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3632a1f9a668bb05",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
